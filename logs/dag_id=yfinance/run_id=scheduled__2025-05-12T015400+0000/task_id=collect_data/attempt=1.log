{"timestamp":"2025-05-12T01:54:01.278458","level":"info","event":"DAG bundles loaded: dags-folder","logger":"airflow.dag_processing.bundles.manager.DagBundlesManager"}
{"timestamp":"2025-05-12T01:54:01.279135","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/yfinance_DAG.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-05-12T01:54:06.317195Z","level":"error","event":"25/05/12 01:54:06 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"task"}
{"timestamp":"2025-05-12T01:54:06.692271Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"task"}
{"timestamp":"2025-05-12T01:54:06.693784Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"task"}
{"timestamp":"2025-05-12T01:54:08.850663Z","level":"error","event":"25/05/12 01:54:08 ERROR SparkContext: Failed to add /opt/airflow/jars/* to Spark environment","chan":"stderr","logger":"task"}
{"timestamp":"2025-05-12T01:54:08.851311Z","level":"error","event":"java.io.FileNotFoundException: Jar /opt/airflow/jars/* not found","chan":"stderr","logger":"task"}
{"timestamp":"2025-05-12T01:54:08.851831Z","level":"error","event":"\tat org.apache.spark.SparkContext.addLocalJarFile$1(SparkContext.scala:2095)","chan":"stderr","logger":"task"}
{"timestamp":"2025-05-12T01:54:08.852265Z","level":"error","event":"\tat org.apache.spark.SparkContext.addJar(SparkContext.scala:2151)","chan":"stderr","logger":"task"}
{"timestamp":"2025-05-12T01:54:08.852729Z","level":"error","event":"\tat org.apache.spark.SparkContext.$anonfun$new$15(SparkContext.scala:521)","chan":"stderr","logger":"task"}
{"timestamp":"2025-05-12T01:54:08.853448Z","level":"error","event":"\tat org.apache.spark.SparkContext.$anonfun$new$15$adapted(SparkContext.scala:521)","chan":"stderr","logger":"task"}
{"timestamp":"2025-05-12T01:54:08.854080Z","level":"error","event":"\tat scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62)","chan":"stderr","logger":"task"}
{"timestamp":"2025-05-12T01:54:08.854658Z","level":"error","event":"\tat scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55)","chan":"stderr","logger":"task"}
{"timestamp":"2025-05-12T01:54:08.855229Z","level":"error","event":"\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49)","chan":"stderr","logger":"task"}
{"timestamp":"2025-05-12T01:54:08.855805Z","level":"error","event":"\tat org.apache.spark.SparkContext.<init>(SparkContext.scala:521)","chan":"stderr","logger":"task"}
{"timestamp":"2025-05-12T01:54:08.856340Z","level":"error","event":"\tat org.apache.spark.api.java.JavaSparkContext.<init>(JavaSparkContext.scala:58)","chan":"stderr","logger":"task"}
{"timestamp":"2025-05-12T01:54:08.856803Z","level":"error","event":"\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)","chan":"stderr","logger":"task"}
{"timestamp":"2025-05-12T01:54:08.857486Z","level":"error","event":"\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:77)","chan":"stderr","logger":"task"}
{"timestamp":"2025-05-12T01:54:08.858344Z","level":"error","event":"\tat java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)","chan":"stderr","logger":"task"}
{"timestamp":"2025-05-12T01:54:08.859025Z","level":"error","event":"\tat java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:500)","chan":"stderr","logger":"task"}
{"timestamp":"2025-05-12T01:54:08.859669Z","level":"error","event":"\tat java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:481)","chan":"stderr","logger":"task"}
{"timestamp":"2025-05-12T01:54:08.860327Z","level":"error","event":"\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:247)","chan":"stderr","logger":"task"}
{"timestamp":"2025-05-12T01:54:08.860808Z","level":"error","event":"\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)","chan":"stderr","logger":"task"}
{"timestamp":"2025-05-12T01:54:08.861351Z","level":"error","event":"\tat py4j.Gateway.invoke(Gateway.java:238)","chan":"stderr","logger":"task"}
{"timestamp":"2025-05-12T01:54:08.861886Z","level":"error","event":"\tat py4j.commands.ConstructorCommand.invokeConstructor(ConstructorCommand.java:80)","chan":"stderr","logger":"task"}
{"timestamp":"2025-05-12T01:54:08.862536Z","level":"error","event":"\tat py4j.commands.ConstructorCommand.execute(ConstructorCommand.java:69)","chan":"stderr","logger":"task"}
{"timestamp":"2025-05-12T01:54:08.863223Z","level":"error","event":"\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)","chan":"stderr","logger":"task"}
{"timestamp":"2025-05-12T01:54:08.863977Z","level":"error","event":"\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106)","chan":"stderr","logger":"task"}
{"timestamp":"2025-05-12T01:54:08.864778Z","level":"error","event":"\tat java.base/java.lang.Thread.run(Thread.java:840)","chan":"stderr","logger":"task"}
{"timestamp":"2025-05-12T01:54:23.676988Z","level":"info","event":"Mengambil data saham AADI.JK dari yfinance...","chan":"stdout","logger":"task"}
{"timestamp":"2025-05-12T01:54:23.677612Z","level":"info","event":"Data saham AADI.JK berhasil disimpan ke MongoDB!","chan":"stdout","logger":"task"}
{"timestamp":"2025-05-12T01:54:23.678161Z","level":"info","event":"Mengambil data saham AALI.JK dari yfinance...","chan":"stdout","logger":"task"}
{"timestamp":"2025-05-12T01:54:23.678705Z","level":"info","event":"Data saham AALI.JK berhasil disimpan ke MongoDB!","chan":"stdout","logger":"task"}
{"timestamp":"2025-05-12T01:54:23.679261Z","level":"info","event":"Mengambil data saham ABBA.JK dari yfinance...","chan":"stdout","logger":"task"}
{"timestamp":"2025-05-12T01:54:23.679671Z","level":"info","event":"Data saham ABBA.JK berhasil disimpan ke MongoDB!","chan":"stdout","logger":"task"}
{"timestamp":"2025-05-12T01:54:23.680199Z","level":"info","event":"Mengambil data saham ABDA.JK dari yfinance...","chan":"stdout","logger":"task"}
{"timestamp":"2025-05-12T01:54:23.680711Z","level":"info","event":"Data saham ABDA.JK berhasil disimpan ke MongoDB!","chan":"stdout","logger":"task"}
{"timestamp":"2025-05-12T01:54:23.681192Z","level":"info","event":"Mengambil data saham ABMM.JK dari yfinance...","chan":"stdout","logger":"task"}
{"timestamp":"2025-05-12T01:54:23.681601Z","level":"info","event":"Data saham ABMM.JK berhasil disimpan ke MongoDB!","chan":"stdout","logger":"task"}
{"timestamp":"2025-05-12T01:54:23.681982Z","level":"info","event":"Semua data saham selesai diproses!","chan":"stdout","logger":"task"}
{"timestamp":"2025-05-12T01:54:23.682517Z","level":"error","event":"\r[Stage 0:>                                                          (0 + 1) / 1]\r\r                                                                                \rTraceback (most recent call last):","chan":"stderr","logger":"task"}
{"timestamp":"2025-05-12T01:54:23.682996Z","level":"error","event":"  File \"/opt/airflow/dags/jobs/YFinance.py\", line 102, in <module>","chan":"stderr","logger":"task"}
{"timestamp":"2025-05-12T01:54:23.683520Z","level":"error","event":"    .save()","chan":"stderr","logger":"task"}
{"timestamp":"2025-05-12T01:54:23.684034Z","level":"error","event":"     ^^^^^^","chan":"stderr","logger":"task"}
{"timestamp":"2025-05-12T01:54:23.684543Z","level":"error","event":"  File \"/home/airflow/.local/lib/python3.12/site-packages/pyspark/sql/readwriter.py\", line 1461, in save","chan":"stderr","logger":"task"}
{"timestamp":"2025-05-12T01:54:23.685253Z","level":"error","event":"    self._jwrite.save()","chan":"stderr","logger":"task"}
{"timestamp":"2025-05-12T01:54:23.686097Z","level":"error","event":"  File \"/home/airflow/.local/lib/python3.12/site-packages/py4j/java_gateway.py\", line 1322, in __call__","chan":"stderr","logger":"task"}
{"timestamp":"2025-05-12T01:54:23.687137Z","level":"error","event":"    return_value = get_return_value(","chan":"stderr","logger":"task"}
{"timestamp":"2025-05-12T01:54:23.687925Z","level":"error","event":"                   ^^^^^^^^^^^^^^^^^","chan":"stderr","logger":"task"}
{"timestamp":"2025-05-12T01:54:23.688391Z","level":"error","event":"  File \"/home/airflow/.local/lib/python3.12/site-packages/pyspark/errors/exceptions/captured.py\", line 185, in deco","chan":"stderr","logger":"task"}
{"timestamp":"2025-05-12T01:54:23.688777Z","level":"error","event":"    raise converted from None","chan":"stderr","logger":"task"}
{"timestamp":"2025-05-12T01:54:23.693203Z","level":"error","event":"pyspark.errors.exceptions.captured.UnsupportedOperationException: MongoCollection already exists","chan":"stderr","logger":"task"}
{"timestamp":"2025-05-12T01:54:24.536151","level":"error","event":"Task failed with exception","logger":"task","error_detail":[{"exc_type":"CalledProcessError","exc_value":"Command '['python', 'dags/jobs/YFinance.py']' returned non-zero exit status 1.","exc_notes":[],"syntax_error":null,"is_cause":false,"frames":[{"filename":"/home/airflow/.local/lib/python3.12/site-packages/airflow/sdk/execution_time/task_runner.py","lineno":825,"name":"run"},{"filename":"/home/airflow/.local/lib/python3.12/site-packages/airflow/sdk/execution_time/task_runner.py","lineno":1088,"name":"_execute_task"},{"filename":"/home/airflow/.local/lib/python3.12/site-packages/airflow/sdk/bases/operator.py","lineno":408,"name":"wrapper"},{"filename":"/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/standard/operators/python.py","lineno":212,"name":"execute"},{"filename":"/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/standard/operators/python.py","lineno":235,"name":"execute_callable"},{"filename":"/home/airflow/.local/lib/python3.12/site-packages/airflow/sdk/execution_time/callback_runner.py","lineno":81,"name":"run"},{"filename":"/opt/airflow/dags/yfinance_DAG.py","lineno":14,"name":"<lambda>"},{"filename":"/usr/local/lib/python3.12/subprocess.py","lineno":571,"name":"run"}]}]}

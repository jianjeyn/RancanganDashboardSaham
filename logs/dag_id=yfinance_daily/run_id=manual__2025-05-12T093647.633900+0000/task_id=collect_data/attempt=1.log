{"timestamp":"2025-05-12T09:36:48.731989","level":"info","event":"DAG bundles loaded: dags-folder","logger":"airflow.dag_processing.bundles.manager.DagBundlesManager"}
{"timestamp":"2025-05-12T09:36:48.734024","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/yfinance_daily.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-05-12T09:37:14.458121Z","level":"info","event":"Mengambil data saham AADI.JK dari yfinance...","chan":"stdout","logger":"task"}
{"timestamp":"2025-05-12T09:37:14.459195Z","level":"info","event":"Data saham AADI.JK berhasil disimpan ke MongoDB!","chan":"stdout","logger":"task"}
{"timestamp":"2025-05-12T09:37:14.460261Z","level":"info","event":"Mengambil data saham AALI.JK dari yfinance...","chan":"stdout","logger":"task"}
{"timestamp":"2025-05-12T09:37:14.461181Z","level":"info","event":"Data saham AALI.JK berhasil disimpan ke MongoDB!","chan":"stdout","logger":"task"}
{"timestamp":"2025-05-12T09:37:14.461851Z","level":"info","event":"Mengambil data saham ABBA.JK dari yfinance...","chan":"stdout","logger":"task"}
{"timestamp":"2025-05-12T09:37:14.462517Z","level":"info","event":"Data saham ABBA.JK berhasil disimpan ke MongoDB!","chan":"stdout","logger":"task"}
{"timestamp":"2025-05-12T09:37:14.463192Z","level":"info","event":"Mengambil data saham ABDA.JK dari yfinance...","chan":"stdout","logger":"task"}
{"timestamp":"2025-05-12T09:37:14.463852Z","level":"info","event":"Data saham ABDA.JK berhasil disimpan ke MongoDB!","chan":"stdout","logger":"task"}
{"timestamp":"2025-05-12T09:37:14.464539Z","level":"info","event":"Mengambil data saham ABMM.JK dari yfinance...","chan":"stdout","logger":"task"}
{"timestamp":"2025-05-12T09:37:14.465296Z","level":"info","event":"Data saham ABMM.JK berhasil disimpan ke MongoDB!","chan":"stdout","logger":"task"}
{"timestamp":"2025-05-12T09:37:14.466125Z","level":"info","event":"Semua data saham selesai diproses!","chan":"stdout","logger":"task"}
{"timestamp":"2025-05-12T09:37:20.428958Z","level":"error","event":"25/05/12 09:37:20 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"task"}
{"timestamp":"2025-05-12T09:37:20.864744Z","level":"error","event":"25/05/12 09:37:20 WARN DependencyUtils: Local jar /opt/airflow/jars/mongo-spark-connector.jar does not exist, skipping.","chan":"stderr","logger":"task"}
{"timestamp":"2025-05-12T09:37:20.866355Z","level":"error","event":"25/05/12 09:37:20 WARN DependencyUtils: Local jar /opt/airflow/jars/mongodb-driver-sync.jar does not exist, skipping.","chan":"stderr","logger":"task"}
{"timestamp":"2025-05-12T09:37:20.867520Z","level":"error","event":"25/05/12 09:37:20 WARN DependencyUtils: Local jar /opt/airflow/jars/mongodb-driver-core.jar does not exist, skipping.","chan":"stderr","logger":"task"}
{"timestamp":"2025-05-12T09:37:20.869308Z","level":"error","event":"25/05/12 09:37:20 WARN DependencyUtils: Local jar /opt/airflow/jars/bson.jar does not exist, skipping.","chan":"stderr","logger":"task"}
{"timestamp":"2025-05-12T09:37:21.195905Z","level":"error","event":"25/05/12 09:37:21 INFO SparkContext: Running Spark version 3.5.5","chan":"stderr","logger":"task"}
{"timestamp":"2025-05-12T09:37:21.196812Z","level":"error","event":"25/05/12 09:37:21 INFO SparkContext: OS info Linux, 5.15.167.4-microsoft-standard-WSL2, amd64","chan":"stderr","logger":"task"}
{"timestamp":"2025-05-12T09:37:21.197791Z","level":"error","event":"25/05/12 09:37:21 INFO SparkContext: Java version 17.0.15","chan":"stderr","logger":"task"}
{"timestamp":"2025-05-12T09:37:21.303858Z","level":"error","event":"25/05/12 09:37:21 INFO ResourceUtils: ==============================================================","chan":"stderr","logger":"task"}
{"timestamp":"2025-05-12T09:37:21.306607Z","level":"error","event":"25/05/12 09:37:21 INFO ResourceUtils: No custom resources configured for spark.driver.","chan":"stderr","logger":"task"}
{"timestamp":"2025-05-12T09:37:21.308279Z","level":"error","event":"25/05/12 09:37:21 INFO ResourceUtils: ==============================================================","chan":"stderr","logger":"task"}
{"timestamp":"2025-05-12T09:37:21.309741Z","level":"error","event":"25/05/12 09:37:21 INFO SparkContext: Submitted application: ReadMongo","chan":"stderr","logger":"task"}
{"timestamp":"2025-05-12T09:37:21.370734Z","level":"error","event":"25/05/12 09:37:21 INFO ResourceProfile: Default ResourceProfile created, executor resources: Map(cores -> name: cores, amount: 1, script: , vendor: , memory -> name: memory, amount: 1024, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)","chan":"stderr","logger":"task"}
{"timestamp":"2025-05-12T09:37:21.398899Z","level":"error","event":"25/05/12 09:37:21 INFO ResourceProfile: Limiting resource is cpu","chan":"stderr","logger":"task"}
{"timestamp":"2025-05-12T09:37:21.400922Z","level":"error","event":"25/05/12 09:37:21 INFO ResourceProfileManager: Added ResourceProfile id: 0","chan":"stderr","logger":"task"}
{"timestamp":"2025-05-12T09:37:21.543779Z","level":"error","event":"25/05/12 09:37:21 INFO SecurityManager: Changing view acls to: airflow","chan":"stderr","logger":"task"}
{"timestamp":"2025-05-12T09:37:21.545771Z","level":"error","event":"25/05/12 09:37:21 INFO SecurityManager: Changing modify acls to: airflow","chan":"stderr","logger":"task"}
{"timestamp":"2025-05-12T09:37:21.548692Z","level":"error","event":"25/05/12 09:37:21 INFO SecurityManager: Changing view acls groups to:","chan":"stderr","logger":"task"}
{"timestamp":"2025-05-12T09:37:21.549726Z","level":"error","event":"25/05/12 09:37:21 INFO SecurityManager: Changing modify acls groups to:","chan":"stderr","logger":"task"}
{"timestamp":"2025-05-12T09:37:21.552356Z","level":"error","event":"25/05/12 09:37:21 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: airflow; groups with view permissions: EMPTY; users with modify permissions: airflow; groups with modify permissions: EMPTY","chan":"stderr","logger":"task"}
{"timestamp":"2025-05-12T09:37:22.586732Z","level":"error","event":"25/05/12 09:37:22 INFO Utils: Successfully started service 'sparkDriver' on port 36217.","chan":"stderr","logger":"task"}
{"timestamp":"2025-05-12T09:37:22.706301Z","level":"error","event":"25/05/12 09:37:22 INFO SparkEnv: Registering MapOutputTracker","chan":"stderr","logger":"task"}
{"timestamp":"2025-05-12T09:37:22.843367Z","level":"error","event":"25/05/12 09:37:22 INFO SparkEnv: Registering BlockManagerMaster","chan":"stderr","logger":"task"}
{"timestamp":"2025-05-12T09:37:22.894700Z","level":"error","event":"25/05/12 09:37:22 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information","chan":"stderr","logger":"task"}
{"timestamp":"2025-05-12T09:37:22.898096Z","level":"error","event":"25/05/12 09:37:22 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up","chan":"stderr","logger":"task"}
{"timestamp":"2025-05-12T09:37:22.918911Z","level":"error","event":"25/05/12 09:37:22 INFO SparkEnv: Registering BlockManagerMasterHeartbeat","chan":"stderr","logger":"task"}
{"timestamp":"2025-05-12T09:37:23.001812Z","level":"error","event":"25/05/12 09:37:23 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-27858695-bfe1-4834-aa4b-f3d8425c71b7","chan":"stderr","logger":"task"}
{"timestamp":"2025-05-12T09:37:23.049962Z","level":"error","event":"25/05/12 09:37:23 INFO MemoryStore: MemoryStore started with capacity 434.4 MiB","chan":"stderr","logger":"task"}
{"timestamp":"2025-05-12T09:37:23.120780Z","level":"error","event":"25/05/12 09:37:23 INFO SparkEnv: Registering OutputCommitCoordinator","chan":"stderr","logger":"task"}
{"timestamp":"2025-05-12T09:37:23.565440Z","level":"error","event":"25/05/12 09:37:23 INFO JettyUtils: Start Jetty 0.0.0.0:4040 for SparkUI","chan":"stderr","logger":"task"}
{"timestamp":"2025-05-12T09:37:23.734864Z","level":"error","event":"25/05/12 09:37:23 INFO Utils: Successfully started service 'SparkUI' on port 4040.","chan":"stderr","logger":"task"}
{"timestamp":"2025-05-12T09:37:23.841440Z","level":"error","event":"25/05/12 09:37:23 ERROR SparkContext: Failed to add /opt/airflow/jars/mongo-spark-connector.jar to Spark environment","chan":"stderr","logger":"task"}
{"timestamp":"2025-05-12T09:37:23.842367Z","level":"error","event":"java.io.FileNotFoundException: Jar /opt/airflow/jars/mongo-spark-connector.jar not found","chan":"stderr","logger":"task"}
{"timestamp":"2025-05-12T09:37:23.843215Z","level":"error","event":"\tat org.apache.spark.SparkContext.addLocalJarFile$1(SparkContext.scala:2095)","chan":"stderr","logger":"task"}
{"timestamp":"2025-05-12T09:37:23.844151Z","level":"error","event":"\tat org.apache.spark.SparkContext.addJar(SparkContext.scala:2151)","chan":"stderr","logger":"task"}
{"timestamp":"2025-05-12T09:37:23.845066Z","level":"error","event":"\tat org.apache.spark.SparkContext.$anonfun$new$15(SparkContext.scala:521)","chan":"stderr","logger":"task"}
{"timestamp":"2025-05-12T09:37:23.845767Z","level":"error","event":"\tat org.apache.spark.SparkContext.$anonfun$new$15$adapted(SparkContext.scala:521)","chan":"stderr","logger":"task"}
{"timestamp":"2025-05-12T09:37:23.846348Z","level":"error","event":"\tat scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62)","chan":"stderr","logger":"task"}
{"timestamp":"2025-05-12T09:37:23.846875Z","level":"error","event":"\tat scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55)","chan":"stderr","logger":"task"}
{"timestamp":"2025-05-12T09:37:23.847453Z","level":"error","event":"\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49)","chan":"stderr","logger":"task"}
{"timestamp":"2025-05-12T09:37:23.848022Z","level":"error","event":"\tat org.apache.spark.SparkContext.<init>(SparkContext.scala:521)","chan":"stderr","logger":"task"}
{"timestamp":"2025-05-12T09:37:23.848580Z","level":"error","event":"\tat org.apache.spark.api.java.JavaSparkContext.<init>(JavaSparkContext.scala:58)","chan":"stderr","logger":"task"}
{"timestamp":"2025-05-12T09:37:23.849166Z","level":"error","event":"\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)","chan":"stderr","logger":"task"}
{"timestamp":"2025-05-12T09:37:23.849903Z","level":"error","event":"\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:77)","chan":"stderr","logger":"task"}
{"timestamp":"2025-05-12T09:37:23.850672Z","level":"error","event":"\tat java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)","chan":"stderr","logger":"task"}
{"timestamp":"2025-05-12T09:37:23.851559Z","level":"error","event":"\tat java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:500)","chan":"stderr","logger":"task"}
{"timestamp":"2025-05-12T09:37:23.852251Z","level":"error","event":"\tat java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:481)","chan":"stderr","logger":"task"}
{"timestamp":"2025-05-12T09:37:23.852897Z","level":"error","event":"\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:247)","chan":"stderr","logger":"task"}
{"timestamp":"2025-05-12T09:37:23.853445Z","level":"error","event":"\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)","chan":"stderr","logger":"task"}
{"timestamp":"2025-05-12T09:37:23.854047Z","level":"error","event":"\tat py4j.Gateway.invoke(Gateway.java:238)","chan":"stderr","logger":"task"}
{"timestamp":"2025-05-12T09:37:23.854574Z","level":"error","event":"\tat py4j.commands.ConstructorCommand.invokeConstructor(ConstructorCommand.java:80)","chan":"stderr","logger":"task"}
{"timestamp":"2025-05-12T09:37:23.855429Z","level":"error","event":"\tat py4j.commands.ConstructorCommand.execute(ConstructorCommand.java:69)","chan":"stderr","logger":"task"}
{"timestamp":"2025-05-12T09:37:23.856871Z","level":"error","event":"\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)","chan":"stderr","logger":"task"}
{"timestamp":"2025-05-12T09:37:23.858443Z","level":"error","event":"\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106)","chan":"stderr","logger":"task"}
{"timestamp":"2025-05-12T09:37:23.859117Z","level":"error","event":"\tat java.base/java.lang.Thread.run(Thread.java:840)","chan":"stderr","logger":"task"}
{"timestamp":"2025-05-12T09:37:23.859947Z","level":"error","event":"25/05/12 09:37:23 ERROR SparkContext: Failed to add /opt/airflow/jars/mongodb-driver-sync.jar to Spark environment","chan":"stderr","logger":"task"}
{"timestamp":"2025-05-12T09:37:23.860697Z","level":"error","event":"java.io.FileNotFoundException: Jar /opt/airflow/jars/mongodb-driver-sync.jar not found","chan":"stderr","logger":"task"}
{"timestamp":"2025-05-12T09:37:23.861319Z","level":"error","event":"\tat org.apache.spark.SparkContext.addLocalJarFile$1(SparkContext.scala:2095)","chan":"stderr","logger":"task"}
{"timestamp":"2025-05-12T09:37:23.861912Z","level":"error","event":"\tat org.apache.spark.SparkContext.addJar(SparkContext.scala:2151)","chan":"stderr","logger":"task"}
{"timestamp":"2025-05-12T09:37:23.862422Z","level":"error","event":"\tat org.apache.spark.SparkContext.$anonfun$new$15(SparkContext.scala:521)","chan":"stderr","logger":"task"}
{"timestamp":"2025-05-12T09:37:23.863094Z","level":"error","event":"\tat org.apache.spark.SparkContext.$anonfun$new$15$adapted(SparkContext.scala:521)","chan":"stderr","logger":"task"}
{"timestamp":"2025-05-12T09:37:23.863718Z","level":"error","event":"\tat scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62)","chan":"stderr","logger":"task"}
{"timestamp":"2025-05-12T09:37:23.864508Z","level":"error","event":"\tat scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55)","chan":"stderr","logger":"task"}
{"timestamp":"2025-05-12T09:37:23.865279Z","level":"error","event":"\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49)","chan":"stderr","logger":"task"}
{"timestamp":"2025-05-12T09:37:23.866081Z","level":"error","event":"\tat org.apache.spark.SparkContext.<init>(SparkContext.scala:521)","chan":"stderr","logger":"task"}
{"timestamp":"2025-05-12T09:37:23.866870Z","level":"error","event":"\tat org.apache.spark.api.java.JavaSparkContext.<init>(JavaSparkContext.scala:58)","chan":"stderr","logger":"task"}
{"timestamp":"2025-05-12T09:37:23.867726Z","level":"error","event":"\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)","chan":"stderr","logger":"task"}
{"timestamp":"2025-05-12T09:37:23.868580Z","level":"error","event":"\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:77)","chan":"stderr","logger":"task"}
{"timestamp":"2025-05-12T09:37:23.869345Z","level":"error","event":"\tat java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)","chan":"stderr","logger":"task"}
{"timestamp":"2025-05-12T09:37:23.872558Z","level":"error","event":"\tat java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:500)","chan":"stderr","logger":"task"}
{"timestamp":"2025-05-12T09:37:23.874919Z","level":"error","event":"\tat java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:481)","chan":"stderr","logger":"task"}
{"timestamp":"2025-05-12T09:37:23.876031Z","level":"error","event":"\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:247)","chan":"stderr","logger":"task"}
{"timestamp":"2025-05-12T09:37:23.878749Z","level":"error","event":"\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)","chan":"stderr","logger":"task"}
{"timestamp":"2025-05-12T09:37:23.879600Z","level":"error","event":"\tat py4j.Gateway.invoke(Gateway.java:238)","chan":"stderr","logger":"task"}
{"timestamp":"2025-05-12T09:37:23.881305Z","level":"error","event":"\tat py4j.commands.ConstructorCommand.invokeConstructor(ConstructorCommand.java:80)","chan":"stderr","logger":"task"}
{"timestamp":"2025-05-12T09:37:23.882341Z","level":"error","event":"\tat py4j.commands.ConstructorCommand.execute(ConstructorCommand.java:69)","chan":"stderr","logger":"task"}
{"timestamp":"2025-05-12T09:37:23.883521Z","level":"error","event":"\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)","chan":"stderr","logger":"task"}
{"timestamp":"2025-05-12T09:37:23.884485Z","level":"error","event":"\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106)","chan":"stderr","logger":"task"}
{"timestamp":"2025-05-12T09:37:23.885704Z","level":"error","event":"\tat java.base/java.lang.Thread.run(Thread.java:840)","chan":"stderr","logger":"task"}
{"timestamp":"2025-05-12T09:37:23.887564Z","level":"error","event":"25/05/12 09:37:23 ERROR SparkContext: Failed to add /opt/airflow/jars/mongodb-driver-core.jar to Spark environment","chan":"stderr","logger":"task"}
{"timestamp":"2025-05-12T09:37:23.888977Z","level":"error","event":"java.io.FileNotFoundException: Jar /opt/airflow/jars/mongodb-driver-core.jar not found","chan":"stderr","logger":"task"}
{"timestamp":"2025-05-12T09:37:23.890051Z","level":"error","event":"\tat org.apache.spark.SparkContext.addLocalJarFile$1(SparkContext.scala:2095)","chan":"stderr","logger":"task"}
{"timestamp":"2025-05-12T09:37:23.890973Z","level":"error","event":"\tat org.apache.spark.SparkContext.addJar(SparkContext.scala:2151)","chan":"stderr","logger":"task"}
{"timestamp":"2025-05-12T09:37:23.892173Z","level":"error","event":"\tat org.apache.spark.SparkContext.$anonfun$new$15(SparkContext.scala:521)","chan":"stderr","logger":"task"}
{"timestamp":"2025-05-12T09:37:23.893145Z","level":"error","event":"\tat org.apache.spark.SparkContext.$anonfun$new$15$adapted(SparkContext.scala:521)","chan":"stderr","logger":"task"}
{"timestamp":"2025-05-12T09:37:23.894239Z","level":"error","event":"\tat scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62)","chan":"stderr","logger":"task"}
{"timestamp":"2025-05-12T09:37:23.895231Z","level":"error","event":"\tat scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55)","chan":"stderr","logger":"task"}
{"timestamp":"2025-05-12T09:37:23.896131Z","level":"error","event":"\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49)","chan":"stderr","logger":"task"}
{"timestamp":"2025-05-12T09:37:23.897110Z","level":"error","event":"\tat org.apache.spark.SparkContext.<init>(SparkContext.scala:521)","chan":"stderr","logger":"task"}
{"timestamp":"2025-05-12T09:37:23.898073Z","level":"error","event":"\tat org.apache.spark.api.java.JavaSparkContext.<init>(JavaSparkContext.scala:58)","chan":"stderr","logger":"task"}
{"timestamp":"2025-05-12T09:37:23.899247Z","level":"error","event":"\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)","chan":"stderr","logger":"task"}
{"timestamp":"2025-05-12T09:37:23.901817Z","level":"error","event":"\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:77)","chan":"stderr","logger":"task"}
{"timestamp":"2025-05-12T09:37:23.904963Z","level":"error","event":"\tat java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)","chan":"stderr","logger":"task"}
{"timestamp":"2025-05-12T09:37:23.908144Z","level":"error","event":"\tat java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:500)","chan":"stderr","logger":"task"}
{"timestamp":"2025-05-12T09:37:23.909102Z","level":"error","event":"\tat java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:481)","chan":"stderr","logger":"task"}
{"timestamp":"2025-05-12T09:37:23.910205Z","level":"error","event":"\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:247)","chan":"stderr","logger":"task"}
{"timestamp":"2025-05-12T09:37:23.911128Z","level":"error","event":"\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)","chan":"stderr","logger":"task"}
{"timestamp":"2025-05-12T09:37:23.912054Z","level":"error","event":"\tat py4j.Gateway.invoke(Gateway.java:238)","chan":"stderr","logger":"task"}
{"timestamp":"2025-05-12T09:37:23.912877Z","level":"error","event":"\tat py4j.commands.ConstructorCommand.invokeConstructor(ConstructorCommand.java:80)","chan":"stderr","logger":"task"}
{"timestamp":"2025-05-12T09:37:23.913780Z","level":"error","event":"\tat py4j.commands.ConstructorCommand.execute(ConstructorCommand.java:69)","chan":"stderr","logger":"task"}
{"timestamp":"2025-05-12T09:37:23.916179Z","level":"error","event":"\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)","chan":"stderr","logger":"task"}
{"timestamp":"2025-05-12T09:37:23.917646Z","level":"error","event":"\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106)","chan":"stderr","logger":"task"}
{"timestamp":"2025-05-12T09:37:23.918653Z","level":"error","event":"\tat java.base/java.lang.Thread.run(Thread.java:840)","chan":"stderr","logger":"task"}
{"timestamp":"2025-05-12T09:37:23.919700Z","level":"error","event":"25/05/12 09:37:23 ERROR SparkContext: Failed to add /opt/airflow/jars/bson.jar to Spark environment","chan":"stderr","logger":"task"}
{"timestamp":"2025-05-12T09:37:23.920670Z","level":"error","event":"java.io.FileNotFoundException: Jar /opt/airflow/jars/bson.jar not found","chan":"stderr","logger":"task"}
{"timestamp":"2025-05-12T09:37:23.921695Z","level":"error","event":"\tat org.apache.spark.SparkContext.addLocalJarFile$1(SparkContext.scala:2095)","chan":"stderr","logger":"task"}
{"timestamp":"2025-05-12T09:37:23.923092Z","level":"error","event":"\tat org.apache.spark.SparkContext.addJar(SparkContext.scala:2151)","chan":"stderr","logger":"task"}
{"timestamp":"2025-05-12T09:37:23.924566Z","level":"error","event":"\tat org.apache.spark.SparkContext.$anonfun$new$15(SparkContext.scala:521)","chan":"stderr","logger":"task"}
{"timestamp":"2025-05-12T09:37:23.925445Z","level":"error","event":"\tat org.apache.spark.SparkContext.$anonfun$new$15$adapted(SparkContext.scala:521)","chan":"stderr","logger":"task"}
{"timestamp":"2025-05-12T09:37:23.926465Z","level":"error","event":"\tat scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62)","chan":"stderr","logger":"task"}
{"timestamp":"2025-05-12T09:37:23.927269Z","level":"error","event":"\tat scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55)","chan":"stderr","logger":"task"}
{"timestamp":"2025-05-12T09:37:23.928047Z","level":"error","event":"\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49)","chan":"stderr","logger":"task"}
{"timestamp":"2025-05-12T09:37:23.928904Z","level":"error","event":"\tat org.apache.spark.SparkContext.<init>(SparkContext.scala:521)","chan":"stderr","logger":"task"}
{"timestamp":"2025-05-12T09:37:23.929925Z","level":"error","event":"\tat org.apache.spark.api.java.JavaSparkContext.<init>(JavaSparkContext.scala:58)","chan":"stderr","logger":"task"}
{"timestamp":"2025-05-12T09:37:23.930814Z","level":"error","event":"\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)","chan":"stderr","logger":"task"}
{"timestamp":"2025-05-12T09:37:23.931699Z","level":"error","event":"\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:77)","chan":"stderr","logger":"task"}
{"timestamp":"2025-05-12T09:37:23.932772Z","level":"error","event":"\tat java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)","chan":"stderr","logger":"task"}
{"timestamp":"2025-05-12T09:37:23.933636Z","level":"error","event":"\tat java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:500)","chan":"stderr","logger":"task"}
{"timestamp":"2025-05-12T09:37:23.934540Z","level":"error","event":"\tat java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:481)","chan":"stderr","logger":"task"}
{"timestamp":"2025-05-12T09:37:23.935333Z","level":"error","event":"\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:247)","chan":"stderr","logger":"task"}
{"timestamp":"2025-05-12T09:37:23.936338Z","level":"error","event":"\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)","chan":"stderr","logger":"task"}
{"timestamp":"2025-05-12T09:37:23.937530Z","level":"error","event":"\tat py4j.Gateway.invoke(Gateway.java:238)","chan":"stderr","logger":"task"}
{"timestamp":"2025-05-12T09:37:23.938496Z","level":"error","event":"\tat py4j.commands.ConstructorCommand.invokeConstructor(ConstructorCommand.java:80)","chan":"stderr","logger":"task"}
{"timestamp":"2025-05-12T09:37:23.941333Z","level":"error","event":"\tat py4j.commands.ConstructorCommand.execute(ConstructorCommand.java:69)","chan":"stderr","logger":"task"}
{"timestamp":"2025-05-12T09:37:23.943133Z","level":"error","event":"\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)","chan":"stderr","logger":"task"}
{"timestamp":"2025-05-12T09:37:23.944320Z","level":"error","event":"\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106)","chan":"stderr","logger":"task"}
{"timestamp":"2025-05-12T09:37:23.945201Z","level":"error","event":"\tat java.base/java.lang.Thread.run(Thread.java:840)","chan":"stderr","logger":"task"}
{"timestamp":"2025-05-12T09:37:24.086754Z","level":"error","event":"25/05/12 09:37:24 INFO Executor: Starting executor ID driver on host e32d8dd2660d","chan":"stderr","logger":"task"}
{"timestamp":"2025-05-12T09:37:24.088427Z","level":"error","event":"25/05/12 09:37:24 INFO Executor: OS info Linux, 5.15.167.4-microsoft-standard-WSL2, amd64","chan":"stderr","logger":"task"}
{"timestamp":"2025-05-12T09:37:24.090215Z","level":"error","event":"25/05/12 09:37:24 INFO Executor: Java version 17.0.15","chan":"stderr","logger":"task"}
{"timestamp":"2025-05-12T09:37:24.115589Z","level":"error","event":"25/05/12 09:37:24 INFO Executor: Starting executor with user classpath (userClassPathFirst = false): ''","chan":"stderr","logger":"task"}
{"timestamp":"2025-05-12T09:37:24.118686Z","level":"error","event":"25/05/12 09:37:24 INFO Executor: Created or updated repl class loader org.apache.spark.util.MutableURLClassLoader@7e56a3df for default.","chan":"stderr","logger":"task"}
{"timestamp":"2025-05-12T09:37:24.189233Z","level":"error","event":"25/05/12 09:37:24 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 36219.","chan":"stderr","logger":"task"}
{"timestamp":"2025-05-12T09:37:24.190274Z","level":"error","event":"25/05/12 09:37:24 INFO NettyBlockTransferService: Server created on e32d8dd2660d:36219","chan":"stderr","logger":"task"}
{"timestamp":"2025-05-12T09:37:24.196218Z","level":"error","event":"25/05/12 09:37:24 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy","chan":"stderr","logger":"task"}
{"timestamp":"2025-05-12T09:37:24.209209Z","level":"error","event":"25/05/12 09:37:24 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, e32d8dd2660d, 36219, None)","chan":"stderr","logger":"task"}
{"timestamp":"2025-05-12T09:37:24.220730Z","level":"error","event":"25/05/12 09:37:24 INFO BlockManagerMasterEndpoint: Registering block manager e32d8dd2660d:36219 with 434.4 MiB RAM, BlockManagerId(driver, e32d8dd2660d, 36219, None)","chan":"stderr","logger":"task"}
{"timestamp":"2025-05-12T09:37:24.223721Z","level":"error","event":"25/05/12 09:37:24 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, e32d8dd2660d, 36219, None)","chan":"stderr","logger":"task"}
{"timestamp":"2025-05-12T09:37:24.227411Z","level":"error","event":"25/05/12 09:37:24 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, e32d8dd2660d, 36219, None)","chan":"stderr","logger":"task"}
{"timestamp":"2025-05-12T09:37:25.494210Z","level":"error","event":"25/05/12 09:37:25 INFO SharedState: Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir.","chan":"stderr","logger":"task"}
{"timestamp":"2025-05-12T09:37:25.574928Z","level":"error","event":"Traceback (most recent call last):","chan":"stderr","logger":"task"}
{"timestamp":"2025-05-12T09:37:25.575833Z","level":"error","event":"  File \"/opt/airflow/jobs/YFinance/daily.py\", line 23, in <module>","chan":"stderr","logger":"task"}
{"timestamp":"2025-05-12T09:37:25.583667Z","level":"error","event":"    df = _spark.read.format(\"mongo\") \\","chan":"stderr","logger":"task"}
{"timestamp":"2025-05-12T09:37:25.584569Z","level":"error","event":"         ^^^^^^^^^^^","chan":"stderr","logger":"task"}
{"timestamp":"2025-05-12T09:37:25.585517Z","level":"error","event":"  File \"/home/airflow/.local/lib/python3.12/site-packages/pyspark/sql/session.py\", line 1706, in read","chan":"stderr","logger":"task"}
{"timestamp":"2025-05-12T09:37:25.586347Z","level":"error","event":"    return DataFrameReader(self)","chan":"stderr","logger":"task"}
{"timestamp":"2025-05-12T09:37:25.587114Z","level":"error","event":"           ^^^^^^^^^^^^^^^^^^^^^","chan":"stderr","logger":"task"}
{"timestamp":"2025-05-12T09:37:25.587955Z","level":"error","event":"  File \"/home/airflow/.local/lib/python3.12/site-packages/pyspark/sql/readwriter.py\", line 70, in __init__","chan":"stderr","logger":"task"}
{"timestamp":"2025-05-12T09:37:25.588683Z","level":"error","event":"    self._jreader = spark._jsparkSession.read()","chan":"stderr","logger":"task"}
{"timestamp":"2025-05-12T09:37:25.589627Z","level":"error","event":"                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^","chan":"stderr","logger":"task"}
{"timestamp":"2025-05-12T09:37:25.590479Z","level":"error","event":"  File \"/home/airflow/.local/lib/python3.12/site-packages/py4j/java_gateway.py\", line 1322, in __call__","chan":"stderr","logger":"task"}
{"timestamp":"2025-05-12T09:37:25.591476Z","level":"error","event":"    return_value = get_return_value(","chan":"stderr","logger":"task"}
{"timestamp":"2025-05-12T09:37:25.592788Z","level":"error","event":"                   ^^^^^^^^^^^^^^^^^","chan":"stderr","logger":"task"}
{"timestamp":"2025-05-12T09:37:25.594908Z","level":"error","event":"  File \"/home/airflow/.local/lib/python3.12/site-packages/pyspark/errors/exceptions/captured.py\", line 185, in deco","chan":"stderr","logger":"task"}
{"timestamp":"2025-05-12T09:37:25.596280Z","level":"error","event":"    raise converted from None","chan":"stderr","logger":"task"}
{"timestamp":"2025-05-12T09:37:25.617070Z","level":"error","event":"25/05/12 09:37:25 INFO SharedState: Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir.","chan":"stderr","logger":"task"}
{"timestamp":"2025-05-12T09:37:25.666647Z","level":"error","event":"pyspark.errors.exceptions.captured.IllegalArgumentException: The value of property spark.mongodb.read.connection.uri must not be null","chan":"stderr","logger":"task"}
{"timestamp":"2025-05-12T09:37:25.667618Z","level":"error","event":"","chan":"stderr","logger":"task"}
{"timestamp":"2025-05-12T09:37:25.668585Z","level":"error","event":"JVM stacktrace:","chan":"stderr","logger":"task"}
{"timestamp":"2025-05-12T09:37:25.669512Z","level":"error","event":"java.lang.IllegalArgumentException: The value of property spark.mongodb.read.connection.uri must not be null","chan":"stderr","logger":"task"}
{"timestamp":"2025-05-12T09:37:25.670354Z","level":"error","event":"\tat org.apache.hadoop.thirdparty.com.google.common.base.Preconditions.checkArgument(Preconditions.java:219)","chan":"stderr","logger":"task"}
{"timestamp":"2025-05-12T09:37:25.671192Z","level":"error","event":"\tat org.apache.hadoop.conf.Configuration.set(Configuration.java:1403)","chan":"stderr","logger":"task"}
{"timestamp":"2025-05-12T09:37:25.672079Z","level":"error","event":"\tat org.apache.hadoop.conf.Configuration.set(Configuration.java:1384)","chan":"stderr","logger":"task"}
{"timestamp":"2025-05-12T09:37:25.672878Z","level":"error","event":"\tat org.apache.spark.sql.internal.SharedState.$anonfun$x$1$2(SharedState.scala:77)","chan":"stderr","logger":"task"}
{"timestamp":"2025-05-12T09:37:25.673646Z","level":"error","event":"\tat scala.collection.immutable.Map$Map3.foreach(Map.scala:376)","chan":"stderr","logger":"task"}
{"timestamp":"2025-05-12T09:37:25.674492Z","level":"error","event":"\tat org.apache.spark.sql.internal.SharedState.<init>(SharedState.scala:69)","chan":"stderr","logger":"task"}
{"timestamp":"2025-05-12T09:37:25.675288Z","level":"error","event":"\tat org.apache.spark.sql.SparkSession.$anonfun$sharedState$1(SparkSession.scala:143)","chan":"stderr","logger":"task"}
{"timestamp":"2025-05-12T09:37:25.675985Z","level":"error","event":"\tat scala.Option.getOrElse(Option.scala:189)","chan":"stderr","logger":"task"}
{"timestamp":"2025-05-12T09:37:25.676845Z","level":"error","event":"\tat org.apache.spark.sql.SparkSession.sharedState$lzycompute(SparkSession.scala:143)","chan":"stderr","logger":"task"}
{"timestamp":"2025-05-12T09:37:25.677702Z","level":"error","event":"\tat org.apache.spark.sql.SparkSession.sharedState(SparkSession.scala:142)","chan":"stderr","logger":"task"}
{"timestamp":"2025-05-12T09:37:25.678741Z","level":"error","event":"\tat org.apache.spark.sql.SparkSession.$anonfun$sessionState$2(SparkSession.scala:162)","chan":"stderr","logger":"task"}
{"timestamp":"2025-05-12T09:37:25.679617Z","level":"error","event":"\tat scala.Option.getOrElse(Option.scala:189)","chan":"stderr","logger":"task"}
{"timestamp":"2025-05-12T09:37:25.680421Z","level":"error","event":"\tat org.apache.spark.sql.SparkSession.sessionState$lzycompute(SparkSession.scala:160)","chan":"stderr","logger":"task"}
{"timestamp":"2025-05-12T09:37:25.681239Z","level":"error","event":"\tat org.apache.spark.sql.SparkSession.sessionState(SparkSession.scala:157)","chan":"stderr","logger":"task"}
{"timestamp":"2025-05-12T09:37:25.681972Z","level":"error","event":"\tat org.apache.spark.sql.DataFrameReader.<init>(DataFrameReader.scala:699)","chan":"stderr","logger":"task"}
{"timestamp":"2025-05-12T09:37:25.682786Z","level":"error","event":"\tat org.apache.spark.sql.SparkSession.read(SparkSession.scala:783)","chan":"stderr","logger":"task"}
{"timestamp":"2025-05-12T09:37:25.683765Z","level":"error","event":"\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)","chan":"stderr","logger":"task"}
{"timestamp":"2025-05-12T09:37:25.684639Z","level":"error","event":"\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)","chan":"stderr","logger":"task"}
{"timestamp":"2025-05-12T09:37:25.685549Z","level":"error","event":"\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)","chan":"stderr","logger":"task"}
{"timestamp":"2025-05-12T09:37:25.686433Z","level":"error","event":"\tat java.base/java.lang.reflect.Method.invoke(Method.java:569)","chan":"stderr","logger":"task"}
{"timestamp":"2025-05-12T09:37:25.687277Z","level":"error","event":"\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)","chan":"stderr","logger":"task"}
{"timestamp":"2025-05-12T09:37:25.688193Z","level":"error","event":"\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)","chan":"stderr","logger":"task"}
{"timestamp":"2025-05-12T09:37:25.689051Z","level":"error","event":"\tat py4j.Gateway.invoke(Gateway.java:282)","chan":"stderr","logger":"task"}
{"timestamp":"2025-05-12T09:37:25.689931Z","level":"error","event":"\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)","chan":"stderr","logger":"task"}
{"timestamp":"2025-05-12T09:37:25.690997Z","level":"error","event":"\tat py4j.commands.CallCommand.execute(CallCommand.java:79)","chan":"stderr","logger":"task"}
{"timestamp":"2025-05-12T09:37:25.691884Z","level":"error","event":"\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)","chan":"stderr","logger":"task"}
{"timestamp":"2025-05-12T09:37:25.692829Z","level":"error","event":"\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106)","chan":"stderr","logger":"task"}
{"timestamp":"2025-05-12T09:37:25.693657Z","level":"error","event":"\tat java.base/java.lang.Thread.run(Thread.java:840)","chan":"stderr","logger":"task"}
{"timestamp":"2025-05-12T09:37:25.694464Z","level":"error","event":"","chan":"stderr","logger":"task"}
{"timestamp":"2025-05-12T09:37:25.841509","level":"error","event":"Task failed with exception","logger":"task","error_detail":[{"exc_type":"CalledProcessError","exc_value":"Command '['python', 'jobs/YFinance/daily.py']' returned non-zero exit status 1.","exc_notes":[],"syntax_error":null,"is_cause":false,"frames":[{"filename":"/home/airflow/.local/lib/python3.12/site-packages/airflow/sdk/execution_time/task_runner.py","lineno":825,"name":"run"},{"filename":"/home/airflow/.local/lib/python3.12/site-packages/airflow/sdk/execution_time/task_runner.py","lineno":1088,"name":"_execute_task"},{"filename":"/home/airflow/.local/lib/python3.12/site-packages/airflow/sdk/bases/operator.py","lineno":408,"name":"wrapper"},{"filename":"/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/standard/operators/python.py","lineno":212,"name":"execute"},{"filename":"/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/standard/operators/python.py","lineno":235,"name":"execute_callable"},{"filename":"/home/airflow/.local/lib/python3.12/site-packages/airflow/sdk/execution_time/callback_runner.py","lineno":81,"name":"run"},{"filename":"/opt/airflow/dags/yfinance_daily.py","lineno":7,"name":"collect_data"},{"filename":"/usr/local/lib/python3.12/subprocess.py","lineno":571,"name":"run"}]}]}
{"timestamp":"2025-05-12T09:37:25.855916Z","level":"error","event":"25/05/12 09:37:25 INFO SparkContext: Invoking stop() from shutdown hook","chan":"stderr","logger":"task"}
{"timestamp":"2025-05-12T09:37:25.858491Z","level":"error","event":"25/05/12 09:37:25 INFO SparkContext: SparkContext is stopping with exitCode 0.","chan":"stderr","logger":"task"}
{"timestamp":"2025-05-12T09:37:25.897138Z","level":"error","event":"25/05/12 09:37:25 INFO SparkUI: Stopped Spark web UI at http://e32d8dd2660d:4040","chan":"stderr","logger":"task"}
{"timestamp":"2025-05-12T09:37:25.967720Z","level":"error","event":"25/05/12 09:37:25 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!","chan":"stderr","logger":"task"}
{"timestamp":"2025-05-12T09:37:26.024009Z","level":"error","event":"25/05/12 09:37:26 INFO MemoryStore: MemoryStore cleared","chan":"stderr","logger":"task"}
{"timestamp":"2025-05-12T09:37:26.026233Z","level":"error","event":"25/05/12 09:37:26 INFO BlockManager: BlockManager stopped","chan":"stderr","logger":"task"}
{"timestamp":"2025-05-12T09:37:26.053845Z","level":"error","event":"25/05/12 09:37:26 INFO BlockManagerMaster: BlockManagerMaster stopped","chan":"stderr","logger":"task"}
{"timestamp":"2025-05-12T09:37:26.063603Z","level":"error","event":"25/05/12 09:37:26 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!","chan":"stderr","logger":"task"}
{"timestamp":"2025-05-12T09:37:26.096592Z","level":"error","event":"25/05/12 09:37:26 INFO SparkContext: Successfully stopped SparkContext","chan":"stderr","logger":"task"}
{"timestamp":"2025-05-12T09:37:26.097763Z","level":"error","event":"25/05/12 09:37:26 INFO ShutdownHookManager: Shutdown hook called","chan":"stderr","logger":"task"}
{"timestamp":"2025-05-12T09:37:26.099694Z","level":"error","event":"25/05/12 09:37:26 INFO ShutdownHookManager: Deleting directory /tmp/spark-733c17ab-8c12-43ae-83f2-4425572db10d","chan":"stderr","logger":"task"}
{"timestamp":"2025-05-12T09:37:26.122132Z","level":"error","event":"25/05/12 09:37:26 INFO ShutdownHookManager: Deleting directory /tmp/spark-95064a54-47c1-4815-acef-c71d46d14350","chan":"stderr","logger":"task"}
{"timestamp":"2025-05-12T09:37:26.131988Z","level":"error","event":"25/05/12 09:37:26 INFO ShutdownHookManager: Deleting directory /tmp/spark-95064a54-47c1-4815-acef-c71d46d14350/pyspark-7b8c9c5d-09a2-4f2b-a511-c09333bec030","chan":"stderr","logger":"task"}
